{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b315b2dc-1f55-46f4-9b62-fa5f99fa1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    PaliGemmaForConditionalGeneration,\n",
    "    PaliGemmaProcessor,\n",
    ")\n",
    "\n",
    "hf_token = \"<HF token here>\"\n",
    "login(token=hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712ee27f-9cc1-4a62-b497-f62d1fb9113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f8b3adeefb41d0a86e0386d5e6cdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# load the model\n",
    "model_id = \"google/paligemma-3b-mix-448\"\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "    model_id, torch_dtype=torch.float16, token=hf_token\n",
    ")\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d7112f-c483-4849-b4fb-23c96395af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(img, prompt):\n",
    "    \n",
    "    # Send text prompt and image as input.\n",
    "    inputs = processor(\n",
    "        text=prompt,\n",
    "        images=img,\n",
    "        padding=\"longest\",\n",
    "        do_convert_rgb=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    model.to(device)\n",
    "    inputs = inputs.to(dtype=model.dtype)\n",
    "\n",
    "    # Get output\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_length=2048)\n",
    "\n",
    "    paligemma_response = processor.decode(output[0], skip_special_tokens=True)[\n",
    "        len(prompt) :\n",
    "    ].lstrip(\"\\n\")\n",
    "\n",
    "    return paligemma_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a97870-8da6-4e2b-bbe6-db8a204baf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashley Hotel West Coast\n",
      "WiFi Internet Service\n",
      "Username: fqpp\n",
      "Password: aaeu\n",
      "Traffic: 1 GB\n",
      "Price: 0.00\n",
      "Validity: 1w\n",
      "Starts: Now\n",
      "Shared Users: 4\n",
      "27/02/2019 11:03:15\n",
      "To logout or check status please type in http://hello.wifi Thank you !\n",
      "\n",
      "⏱️ Inference time: 3.108 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"ocr\"\n",
    "\n",
    "opencv_img = cv2.cvtColor(\n",
    "    cv2.imread(\"password.jpg\"), cv2.COLOR_BGR2RGB\n",
    ")\n",
    "\n",
    "time_taken = [] \n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    response = get_result(opencv_img, prompt)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    time_taken.append(inference_time)\n",
    "\n",
    "print(response)\n",
    "print(f\"\\n⏱️ Inference time: {np.average(time_taken):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09290476-a3e1-4ba2-a324-f2e5cff3964a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
